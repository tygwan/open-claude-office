# resumely — Experience Blocks

> 6블록 사고력 템플릿 기반 경험 구조화. 분석 데이터 + 사용자 인터뷰 결합.
> 생성일: 2026-02-22 | 경험 수: 5개

---

## Experience 1: AI 생성 품질 제어 — "AI가 쓴 티"를 없애는 3중 검증 체계

### 목표(KPI)
한국 취업 시장에서 인사담당자가 AI 생성물로 감별하지 못하는 수준의 자기소개서 품질 달성. 구체적으로: 금지 문구(클리셰) 0개, 글자수 정확도 ±10% 이내, K-STAR-K 준수(정량적 결과 패턴 2개 이상 포함).

### 현상(문제 증상)
LLM이 생성하는 자기소개서에 "열정을 가지고", "기여하겠습니다", "성장할 수 있었습니다" 같은 AI 특유의 추상적 클리셰가 거의 매번 반복 발생. 글자수 제한(±10%)을 정확히 맞추지 못하는 빈도도 높았음. 경험 많은 인사담당자에게 즉시 감별되어 서류 탈락으로 직결되는 문제. (출처: narrative.md Challenge 1)

### 원인 가설
1. **프롬프트의 지시 부족** → 검증: 시스템 프롬프트에 "~하지 마라"는 명시적 금지 지시를 추가하고 클리셰 발생률 비교. 금지 지시 없으면 LLM이 학습 데이터의 최빈 패턴(클리셰)으로 회귀 (사용자 답변)
2. **구조화 부족 (자유 서술)** → 검증: K-STAR-K 같은 구조를 강제하지 않고 자유 작성시키면, LLM이 빈 공간을 추상적 표현으로 채움. 구조 강제 전후 클리셰 빈도 비교 (사용자 답변)
3. **검증 루프 부재** → 검증: 생성 후 자동 품질 체크 없이 출력을 그대로 전달하면 클리셰가 사용자에게 도달. 검증 추가 전후 최종 출력 품질 비교 (출처: architecture.md Decision 4)

### 판단 기준(Decision Rule)
- **조건 1**: 한국어 금지 표현/패턴은 범용 LLM이 사전에 학습하지 못한 도메인 특수 지식 → **전략: 명시적 금지 목록(9개 한국어 + 7개 영어) 필수** ← 채택
- **조건 2**: 프롬프트(사전 예방)만으로는 100% 방지 불가 → **전략: 사전 예방 + 사후 교정 조합** ← 채택. "프롬프트 예방만으로 충분하면 검증 불필요, 불충분하면 검증 레이어 추가"가 핵심 판단 기준
- **기각된 대안**: 무조건 2회 생성 후 선택 → 비용 2배이며 대부분 1차 생성이 충분. 임계값 초과 시에만 재시도하여 비용 절감 (사용자 답변 + 출처: architecture.md Decision 4)

### 실행
1. **Few-shot Examples 내장** — 좋은/나쁜 예시를 `prompts.ts`(960줄)에 포함. LLM이 "무엇이 클리셰인지" 경계를 학습하도록 유도 — 도구: 시스템 프롬프트
2. **validate-output.ts 검증 엔진 구축** (445줄) — 글자수 정확도, 금지 문구 16개 탐지, K-STAR-K 준수(정량적 결과 패턴 2개+), 4종 안티패턴(나열식/배경 장황/AI투/판단근거 부재) 자동 감지 — 도구: Zod 스키마 + 정규식
3. **조건부 자동 재시도** — ±30% 글자수 이탈 또는 금지 문구 3개+ 시 corrective feedback 포함하여 1회 자동 재생성. 추가 크레딧 없이 품질 향상 — 도구: streamObject retry with feedback prompt
4. **검증**: 재시도 실패 시에도 1차 결과를 유지하여 항상 결과 반환 (사용자 경험 보장)

### 결과

| 지표 | Before | After | 변화 |
|------|--------|-------|------|
| 클리셰 발생률 | 거의 매번 포함 | 대부분 제거 | 체감 대폭 감소 (사용자 답변) |
| 금지 문구 탐지 범위 | 0개 | 16개 (KO 9 + EN 7) | 한국어 도메인 특화 |
| 안티패턴 감지 | 없음 | 4종 자동 감지 | 나열식/장황/AI투/판단근거 부재 |
| 사용자 수동 재생성 | 필요 | 자동 재시도로 감소 | UX 개선 + 크레딧 절약 |

**핵심 성과**: 한국 자기소개서 도메인에 특화된 3중 품질 보증 체계(Few-shot + 금지목록 + 자동 재시도)로 AI 클리셰 발생률을 체감 대폭 감소시킴 [아직 정량 측정 전]

---

## Experience 2: SSE 실시간 스트리밍 아키텍처 — 체감 대기 30초 → 2~3초

### 목표(KPI)
자기소개서 생성 시 사용자 체감 대기 시간을 ~30초에서 최초 콘텐츠 노출 ~2-3초로 단축. 생성 중 진행 상태(검증/재시도/에러)를 실시간 피드백.

### 현상(문제 증상)
LLM 기반 자기소개서 생성에 평균 ~30초 소요. 이 동안 사용자는 "작동하고 있는지" 확인 불가. 또한 생성 후 품질 검증 + 자동 재시도라는 후처리 단계가 필요하여, 단순 스트리밍으로는 대응 불가능. (출처: narrative.md Challenge 2)

### 원인 가설
1. **후처리 이벤트 전달 불가** → 검증: Vercel AI SDK의 `experimental_useObject` 훅은 JSON 스트림만 지원. 검증/재시도/에러 등 생성 외 이벤트를 클라이언트에 전달할 채널이 없음 (사용자 답변)
2. **상태 관리 한계** → 검증: useObject의 단순 partial/complete 2단계로는 5-phase FSM(generating→validating→retrying→complete→error) 표현 불가. 복잡한 생명주기를 클라이언트가 인지해야 적절한 UI 렌더링 가능 (사용자 답변)
3. **커스텀 요구사항 복합** → 검증: AbortController 기반 사용자 취소, 분할 청크 버퍼 누적, 비-SSE 폴백까지 포함하면 기본 훅의 추상화 수준으로는 대응 불가 (사용자 답변)

### 판단 기준(Decision Rule)
- **조건**: 생성 외 이벤트(검증/재시도/에러) 전달 + 5-phase 상태 관리 + AbortController가 모두 필요 → **전략 A**: 커스텀 SSE 프로토콜 구현 ← 채택
- **전략 B**: `experimental_useObject` 기본 훅 사용 → 후처리 이벤트 전달 불가, FSM 표현 불가로 기각
- **전략 C**: WebSocket → Vercel 서버리스에서 연결 유지 어려움, 관리 복잡도 과도
- **전략 D**: Polling → 지연 시간 + 불필요한 DB 쿼리, 실시간성 부족
- **기각 근거**: "요구사항이 기본 훅으로 충족 가능하면 기본 훅, 불가능하면 커스텀"이 판단 기준. 3가지 요구사항 모두 기본 훅 불가 → 커스텀 필수 (사용자 답변)

### 실행
1. **커스텀 SSE 프로토콜 설계** — 6종 이벤트 타입(started/partial/validating/retrying/complete/error) 정의. `data: {...}\n\n` 형식으로 인코딩 — 도구: ReadableStream + TextEncoder
2. **서버 스트리밍 구현** (`generate/route.ts` 567줄) — `streamObject()`로 Zod 스키마 기반 JSON 스트리밍 시작 → 각 phase에서 SSE 이벤트 전송
3. **클라이언트 훅 구현** (`use-generate-stream.ts` 167줄) — `ReadableStream` + `TextDecoder`로 SSE 청크 파싱. 분할 청크 버퍼 누적, 5-phase FSM 관리, AbortController 기반 취소
4. **검증**: 비-SSE 폴백 경로, `useTransition`으로 UI freeze 제거

### 결과

| 지표 | Before | After | 변화 |
|------|--------|-------|------|
| 최초 콘텐츠 노출 | ~30초 (전체 대기) | ~2-3초 | 10배+ 체감 개선 |
| 진행 상태 피드백 | 없음 (스피너만) | 6종 실시간 이벤트 | 사용자 불확실성 해소 |
| 사용자 취소 | 불가 | AbortController 지원 | UX 개선 |
| 후처리 가시성 | 없음 | validating/retrying 표시 | 품질 보증 과정 투명화 |

**핵심 성과**: 커스텀 SSE 프로토콜 + 5-phase FSM으로 체감 대기 시간 10배+ 단축, 생성-검증-재시도 전체 생명주기를 실시간 시각화

---

## Experience 3: Signal-weighted 경험-직무 매칭 알고리즘

### 목표(KPI)
사용자의 경험 데이터(최대 42+ 항목)와 채용공고 요구사항을 정밀 매칭하여, 상위 추천 경험의 직무 적합성을 극대화. 최소 추천 점수(MIN_RECOMMEND_SCORE: 2.4) 이상만 추천.

### 현상(문제 증상)
단순 키워드 매칭으로 경험-공고를 연결하면 두 가지 문제: (1) 한영 혼용 기술 용어(Docker↔도커, BIM↔건축정보모델링) 매칭 실패, (2) 경험 카테고리별 중요도(project vs personality) 차이를 반영하지 못해 부적합한 경험이 상위 추천됨. (출처: narrative.md Challenge 3)

### 원인 가설
1. **한영 동의어 부재** → 검증: "React"와 "리액트"를 같은 토큰으로 인식하지 못하면 50%+ 매칭 누락. 동의어 사전 추가 전후 매칭률 비교 (출처: context-matching.ts)
2. **균등 가중치의 한계** → 검증: 모든 신호(mustHave, responsibilities, keywords 등)를 동일 가중치로 처리하면, 채용공고에서 "필수"로 명시한 역량과 "우대"를 동일하게 취급. 인사담당자 관점에서 서류 심사 기준과 괴리 발생 (사용자 답변)
3. **카테고리 미분화** → 검증: project/skill 경험(직무 핵심)과 personality/growth 경험(보조)을 동일 가중치로 점수화하면 노이즈 증가 (출처: context-matching.ts:50-76)

### 판단 기준(Decision Rule)
가중치 결정에 3가지 접근을 복합 적용:
- **인사담당자 관점 역추론**: 채용공고에서 '필수 조건'으로 명시 > '담당 업무' > '우대 사항' 순으로 서류 탈락에 영향. 이 우선순위를 수치화 → mustHave(2.2x) > responsibilities(1.8x) > requirements(1.6x) > keywords(1.4x) (사용자 답변)
- **A/B 테스트 + 반복 조정**: 실제 공고와 경험 데이터로 매칭 실행하여 추천 결과의 적합성을 체감으로 반복 튜닝 (사용자 답변)
- **정보이론 기반 추정**: TF-IDF 유사 개념 — 공고에서 희소하고 명시적일수록 가중치 높게, 일반적 키워드는 낮게 설정 (사용자 답변)
- **기각된 대안**: 균등 가중치 → 필수/우대 구분 불가. ML 기반 학습 → 학습 데이터 부족(초기 서비스)

### 실행
1. **한영 동의어 사전 구축** — 30+ 양방향 확장 매핑(AI↔인공지능, React↔리액트, Docker↔도커 등 48개) — 도구: 수동 매핑 + context-matching.ts
2. **9-tier 신호 가중치 시스템** — mustHave(2.2x), responsibilities(1.8x), requirements(1.6x), keywords(1.4x), niceToHave(1.2x), context(0.5x) 등 — 도구: context-matching.ts 392줄
3. **카테고리별 가중치** — project/skill: 2x, problem: 1.5x, collaboration/personality/growth: 1x
4. **점수 기반 정렬** — MIN_RECOMMEND_SCORE(2.4) 이상만 추천(max 8개) + 나머지는 other로 분류

### 결과

| 지표 | Before (단순 키워드) | After (Signal-weighted) | 변화 |
|------|---------------------|------------------------|------|
| 한영 용어 매칭 | 매칭 실패 빈번 | 48개 동의어 양방향 확장 | 매칭 누락 대폭 감소 |
| 추천 적합도 | 부적합 경험 상위 노출 | 직무 핵심 경험 우선 | 체감 적합성 향상 |
| 신호 계층화 | 균등 (1x) | 9-tier (0.5x~2.2x) | 필수/우대 구분 |
| 추천 수 | 전체 표시 | max 8개 (2.4점+) | 노이즈 제거 |

**핵심 성과**: 인사담당자 관점 역추론 + 정보이론 + 반복 튜닝을 결합한 9-tier 가중치 매칭으로, 경험-직무 추천의 질적 도약 달성

---

## Experience 4: 23일 만에 프로덕션 SaaS 구축 — 극한 속도의 풀스택 개발

### 목표(KPI)
OAuth 인증, RLS 보안, 결제 시스템, Multi-model AI, i18n, 실시간 스트리밍, 품질 검증까지 포함한 프로덕션 레벨 SaaS를 최소 시간 내 구축하여 시장 검증 개시. 실제 달성: 23일.

### 현상(문제 증상)
자기소개서 AI 서비스라는 아이디어를 최대한 빠르게 시장에서 검증해야 하는 상황. 인증/결제/AI/i18n/보안 등 필수 요소를 직접 구현하면 각각 1~2주씩 소요. 개인 프로젝트로서 리소스 제한. (출처: narrative.md Challenge 4)

### 원인 가설
1. **백엔드 인프라 직접 구현의 시간 비용** → 검증: Auth, DB, Storage를 각각 구현하면 최소 2주+. BaaS 위임 시 수일로 단축 가능한지 검증 (사용자 답변)
2. **멀티모델 통합의 복잡도** → 검증: 3개 프로바이더 직접 통합 vs SDK 추상화. 직접 구현 시 모델 교체마다 코드 변경 필요 (출처: architecture.md Decision 3)
3. **핵심 로직 검증 없이 스택 선택의 위험** → 검증: 전체 프레임워크 세팅 후 핵심 로직이 동작하지 않으면 전체 시간 낭비 (사용자 답변)

### 판단 기준(Decision Rule)
- **조건 1**: "커스텀 백엔드 필요 없으면 BaaS" → **Supabase로 Auth + DB(RLS) + Storage 전체 위임** ← 채택. 커스텀 서버 구축 대비 2주+ 절감. (사용자 답변)
- **조건 2**: "로직 검증이 안 되면 스택 선택 의미 없음" → **프로토타입 검증 후 전환** ← 채택. 단일 파일(`cover-letter-assistant.tsx`)로 핵심 플로우(경험→AI→자소서) 검증 후 풀스택 전환. (사용자 답변)
- **조건 3**: "멀티모델 필요하면 Vercel AI SDK, 단일 모델이면 직접 호출" → SDK 추상화로 모델 교체 1줄 (출처: architecture.md)
- **기각된 대안**: 커스텀 Express/Fastify 백엔드 → 인증/DB 직접 구현 시 시간 초과. 단일 모델 → 프로바이더 장애 시 전체 서비스 중단.

### 실행
1. **프로토타입 검증** — `cover-letter-assistant.tsx` 단일 파일로 핵심 로직 PoC (경험 업로드 → AI 분석 → 공고 비교 → 생성) — 도구: React, Vercel AI SDK
2. **풀스택 전환** — Next.js 16 App Router + Supabase(Auth+DB+Storage) + Vercel AI SDK + shadcn/ui + Tailwind CSS 4 조합으로 전환
3. **BaaS 극대화** — Supabase RLS로 멀티테넌시, Signup trigger로 자동 온보딩, 3-client 패턴(browser/server/middleware)
4. **AI 페어 프로그래밍** — Claude Code와 협업으로 구현 속도 가속
5. **단계적 기능 확장** — Phase 1 Foundation → Phase 2 Core → Phase 3 Monetization → SSE → Experience Hub/Resume Builder

### 결과

| 지표 | Before (계획) | After (실제) | 변화 |
|------|--------------|-------------|------|
| 개발 기간 | 미정 | 23일 | 프로토타입→프로덕션 |
| 코드 규모 | 0 | 19,255줄 TS + 68,969줄 총 삽입 | 풀스택 SaaS |
| DB 스키마 | 0 | 10 테이블 + 11 마이그레이션 | Supabase RLS |
| 커밋 수 | 0 | 22 | 평균 ~1일 1커밋 |
| 기능 범위 | 자소서 생성기 | 통합 취업 준비 플랫폼 | 범위 확장 |

**핵심 성과**: BaaS 의존도 최대화 + 프로토타입 우선 검증 + AI 페어 프로그래밍으로 23일 만에 인증/결제/AI/i18n/보안이 모두 포함된 프로덕션 SaaS 구축

---

## Experience 5: Multi-model AI + 3-Tier 크레딧 과금 시스템

### 목표(KPI)
다양한 품질/비용 선호의 사용자를 동시에 만족시키는 과금 모델 구축. 신규 사용자의 진입 장벽 최소화(무료 크레딧 5개 → fast 5회 또는 balanced 1회 체험).

### 현상(문제 증상)
단일 AI 모델로는 가격 민감 사용자와 품질 중시 사용자를 동시에 만족 불가. 단일 프로바이더 의존 시 장애 발생하면 전체 서비스 중단. MVP 단계에서 구독제는 가격 실험이 어려움. (출처: architecture.md Decision 3)

### 원인 가설
1. **모델별 비용-품질 편차** → 검증: Haiku(저가/빠름) vs Opus(고가/고품질) 사이에 토큰 단가 10배+ 차이. 단일 가격은 한쪽이 불만족 (출처: models.ts)
2. **프로바이더 단일 장애점** → 검증: Anthropic API 장애 시 서비스 전체 중단. 3개 프로바이더면 fallback 가능 (출처: architecture.md)
3. **진입 장벽과 전환율의 트레이드오프** → 검증: 유료 진입이면 사용자 이탈, 완전 무료면 수익 불가. 크레딧 체험 → 유료 전환 경로 필요

### 판단 기준(Decision Rule)
- **가격 결정 기준**: **API 비용 역산** 기반. 각 모델의 토큰 단가를 기준으로 원가 대비 마진을 설정하여 크레딧 비용 산출. Haiku(저원가)=fast 1cr, Opus(고원가)=premium 10cr (사용자 답변)
- **조건**: "무료 크레딧으로 fast 모델 체험 → 품질 인식 후 balanced/premium 전환 유도"가 핵심 전환 전략
- **기각된 대안**: 구독제(월정액) → MVP 단계에서 가격 실험 어려움. 종량제가 시장 검증에 유리. 단일 모델 → 의존성 집중 리스크

### 실행
1. **3-프로바이더 통합** — Anthropic(Claude Haiku/Sonnet/Opus), OpenAI(GPT-4o-mini/4o/5-mini/5), Google(Gemini 2.0 Flash) — 도구: Vercel AI SDK `getProvider()` 팩토리
2. **3-Tier 크레딧 분류** — fast(1~2cr): Haiku, GPT-4o-mini, Gemini Flash / balanced(3cr): Sonnet, GPT-5-mini / premium(10cr): Opus, GPT-4o, GPT-5
3. **PortOne V2 결제 통합** — 4개 패키지(3,000~18,000 KRW), HMAC-SHA256 웹훅 검증
4. **OCC 크레딧 차감** — Optimistic Concurrency Control로 동시 요청 시 중복 차감 방지 (출처: architecture.md Decision 2)
5. **분석 무료화** — `analyze` API는 GPT-4o-mini(저가) 사용, 크레딧 미차감. 진입 장벽 최소화

### 결과

| 지표 | Before | After | 변화 |
|------|--------|-------|------|
| AI 모델 수 | 0 | 8개 (3 프로바이더) | 다양성 확보 |
| 크레딧 tier | 없음 | 3-tier (fast/balanced/premium) | 가격 세분화 |
| 결제 수단 | 없음 | PortOne V2 (한국 PG) | 수익화 가능 |
| 신규 사용자 진입 | 유료만 | 무료 5cr 체험 | 진입 장벽 제거 |
| 프로바이더 장애 대응 | 전체 중단 | 다른 프로바이더 fallback 가능 | 가용성 향상 |

**핵심 성과**: API 비용 역산 기반 3-Tier 크레딧 과금으로 비용-품질 선택권을 사용자에게 제공하면서, 무료 체험 → 유료 전환 경로를 설계

---

## Gap Summary

| 경험 | 목표 | 현상 | 가설 | 판단기준 | 실행 | 결과 |
|------|------|------|------|---------|------|------|
| Exp 1: AI 품질 제어 | O | O | O | O | O | △ |
| Exp 2: SSE 스트리밍 | O | O | O | O | O | O |
| Exp 3: Signal-weighted 매칭 | O | O | O | O | O | △ |
| Exp 4: 23일 SaaS | O | O | O | O | O | O |
| Exp 5: Multi-model 크레딧 | O | O | O | O | O | △ |

> O = 완성, △ = 부분(정량 측정 미완 — 서비스 초기 단계), X = 미확인
> △ 항목은 서비스 운영 데이터 축적 후 정량화 가능
